{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv('C:/Users/My PC/Desktop/Machine Learning/Data Engineer/tree_class_feats.csv')\n",
    "y=pd.read_csv('C:/Users/My PC/Desktop/Machine Learning/Data Engineer/tree_class_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "      <th>feature 3</th>\n",
       "      <th>feature 4</th>\n",
       "      <th>feature 5</th>\n",
       "      <th>feature 6</th>\n",
       "      <th>feature 7</th>\n",
       "      <th>feature 8</th>\n",
       "      <th>feature 9</th>\n",
       "      <th>feature 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.722029</td>\n",
       "      <td>-4.689223</td>\n",
       "      <td>-0.207066</td>\n",
       "      <td>2.498555</td>\n",
       "      <td>2.883010</td>\n",
       "      <td>1.579690</td>\n",
       "      <td>-2.720014</td>\n",
       "      <td>-1.246192</td>\n",
       "      <td>1.168185</td>\n",
       "      <td>1.400007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236202</td>\n",
       "      <td>-2.412059</td>\n",
       "      <td>-2.977042</td>\n",
       "      <td>2.837931</td>\n",
       "      <td>4.201749</td>\n",
       "      <td>0.536090</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>-1.308043</td>\n",
       "      <td>3.728172</td>\n",
       "      <td>-1.198629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.592300</td>\n",
       "      <td>-3.678390</td>\n",
       "      <td>-0.282953</td>\n",
       "      <td>0.912839</td>\n",
       "      <td>1.055228</td>\n",
       "      <td>1.235441</td>\n",
       "      <td>-3.378884</td>\n",
       "      <td>-1.117221</td>\n",
       "      <td>-0.274793</td>\n",
       "      <td>0.098392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.579346</td>\n",
       "      <td>-1.135482</td>\n",
       "      <td>0.734795</td>\n",
       "      <td>-3.840698</td>\n",
       "      <td>-0.362227</td>\n",
       "      <td>2.641352</td>\n",
       "      <td>-3.080336</td>\n",
       "      <td>-1.728918</td>\n",
       "      <td>-2.738785</td>\n",
       "      <td>-1.061155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.962439</td>\n",
       "      <td>1.754583</td>\n",
       "      <td>-1.145055</td>\n",
       "      <td>1.857364</td>\n",
       "      <td>0.989132</td>\n",
       "      <td>2.567482</td>\n",
       "      <td>2.058646</td>\n",
       "      <td>-7.009674</td>\n",
       "      <td>-2.108419</td>\n",
       "      <td>1.437935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature 1  feature 2  feature 3  feature 4  feature 5  feature 6  \\\n",
       "0   1.722029  -4.689223  -0.207066   2.498555   2.883010   1.579690   \n",
       "1   0.236202  -2.412059  -2.977042   2.837931   4.201749   0.536090   \n",
       "2   0.592300  -3.678390  -0.282953   0.912839   1.055228   1.235441   \n",
       "3   1.579346  -1.135482   0.734795  -3.840698  -0.362227   2.641352   \n",
       "4  -2.962439   1.754583  -1.145055   1.857364   0.989132   2.567482   \n",
       "\n",
       "   feature 7  feature 8  feature 9  feature 10  \n",
       "0  -2.720014  -1.246192   1.168185    1.400007  \n",
       "1   0.266874  -1.308043   3.728172   -1.198629  \n",
       "2  -3.378884  -1.117221  -0.274793    0.098392  \n",
       "3  -3.080336  -1.728918  -2.738785   -1.061155  \n",
       "4   2.058646  -7.009674  -2.108419    1.437935  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow import random\n",
    "np.random.seed(42)\n",
    "random.set_seed(42)\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Activation\n",
    "model.add(Dense(10, activation='tanh', input_dim=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5,activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 281\n",
      "Trainable params: 281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 7s 815us/step - loss: 0.1332 - val_loss: 0.1430\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 4s 479us/step - loss: 0.1330 - val_loss: 0.1428\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 4s 440us/step - loss: 0.1329 - val_loss: 0.1426\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 4s 443us/step - loss: 0.1327 - val_loss: 0.1423\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 4s 476us/step - loss: 0.1325 - val_loss: 0.1421\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 4s 476us/step - loss: 0.1324 - val_loss: 0.1418\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 3s 396us/step - loss: 0.1322 - val_loss: 0.1416\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 3s 391us/step - loss: 0.1321 - val_loss: 0.1414\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 3s 410us/step - loss: 0.1320 - val_loss: 0.1412\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 3s 399us/step - loss: 0.1318 - val_loss: 0.1410\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 3s 399us/step - loss: 0.1317 - val_loss: 0.1408\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 3s 391us/step - loss: 0.1316 - val_loss: 0.1406\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 3s 410us/step - loss: 0.1315 - val_loss: 0.1405\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 3s 437us/step - loss: 0.1314 - val_loss: 0.1403\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 3s 410us/step - loss: 0.1312 - val_loss: 0.1402\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 3s 424us/step - loss: 0.1311 - val_loss: 0.1400\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 4s 510us/step - loss: 0.1310 - val_loss: 0.1399\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 4s 506us/step - loss: 0.1309 - val_loss: 0.1398\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 4s 500us/step - loss: 0.1308 - val_loss: 0.1397\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 4s 484us/step - loss: 0.1307 - val_loss: 0.1395\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 4s 503us/step - loss: 0.1306 - val_loss: 0.1394\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 4s 538us/step - loss: 0.1305 - val_loss: 0.1393\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 4s 503us/step - loss: 0.1304 - val_loss: 0.1393\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 4s 499us/step - loss: 0.1303 - val_loss: 0.1392\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 4s 537us/step - loss: 0.1302 - val_loss: 0.1391\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 4s 465us/step - loss: 0.1302 - val_loss: 0.1390\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 4s 500us/step - loss: 0.1301 - val_loss: 0.1390\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 3s 422us/step - loss: 0.1300 - val_loss: 0.1389\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 0.1299 - val_loss: 0.1389\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 3s 386us/step - loss: 0.1298 - val_loss: 0.1388\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 3s 423us/step - loss: 0.1297 - val_loss: 0.1388\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 3s 393us/step - loss: 0.1296 - val_loss: 0.1388\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 3s 426us/step - loss: 0.1295 - val_loss: 0.1388\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 3s 400us/step - loss: 0.1294 - val_loss: 0.1387\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 3s 385us/step - loss: 0.1293 - val_loss: 0.1387\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 3s 412us/step - loss: 0.1292 - val_loss: 0.1387\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.1291 - val_loss: 0.1387\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 3s 384us/step - loss: 0.1290 - val_loss: 0.1387\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 3s 382us/step - loss: 0.1289 - val_loss: 0.1387\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 3s 388us/step - loss: 0.1288 - val_loss: 0.1387\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: 0.1287 - val_loss: 0.1388\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 3s 392us/step - loss: 0.1286 - val_loss: 0.1388\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.1285 - val_loss: 0.1388\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 3s 382us/step - loss: 0.1284 - val_loss: 0.1389\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.1283 - val_loss: 0.1389\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 3s 400us/step - loss: 0.1282 - val_loss: 0.1390\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 3s 390us/step - loss: 0.1281 - val_loss: 0.1390\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 3s 384us/step - loss: 0.1280 - val_loss: 0.1391\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 3s 387us/step - loss: 0.1279 - val_loss: 0.1391\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 3s 384us/step - loss: 0.1279 - val_loss: 0.1392\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 3s 395us/step - loss: 0.1278 - val_loss: 0.1393\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 0.1277 - val_loss: 0.1393\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 3s 392us/step - loss: 0.1276 - val_loss: 0.1394\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.1275 - val_loss: 0.1395\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 3s 383us/step - loss: 0.1275 - val_loss: 0.1396\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 3s 389us/step - loss: 0.1274 - val_loss: 0.1397\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 3s 405us/step - loss: 0.1273 - val_loss: 0.1398\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.1272 - val_loss: 0.1399\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 3s 383us/step - loss: 0.1271 - val_loss: 0.1400\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 3s 385us/step - loss: 0.1270 - val_loss: 0.1401\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 3s 380us/step - loss: 0.1270 - val_loss: 0.1402\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 3s 410us/step - loss: 0.1269 - val_loss: 0.1403\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 3s 379us/step - loss: 0.1268 - val_loss: 0.1404\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 3s 386us/step - loss: 0.1267 - val_loss: 0.1404\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 3s 386us/step - loss: 0.1266 - val_loss: 0.1405\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 3s 380us/step - loss: 0.1265 - val_loss: 0.1406\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.1265 - val_loss: 0.1407\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.1264 - val_loss: 0.1408\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 3s 382us/step - loss: 0.1263 - val_loss: 0.1408\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 3s 388us/step - loss: 0.1262 - val_loss: 0.1409\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 3s 384us/step - loss: 0.1262 - val_loss: 0.1410\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 3s 418us/step - loss: 0.1261 - val_loss: 0.1410\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 3s 415us/step - loss: 0.1260 - val_loss: 0.1411\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 3s 395us/step - loss: 0.1260 - val_loss: 0.1411\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.1259 - val_loss: 0.1412\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 3s 387us/step - loss: 0.1258 - val_loss: 0.1412\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 3s 414us/step - loss: 0.1258 - val_loss: 0.1413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 3s 380us/step - loss: 0.1257 - val_loss: 0.1413\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 3s 429us/step - loss: 0.1256 - val_loss: 0.1414\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 3s 384us/step - loss: 0.1256 - val_loss: 0.1415\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 3s 388us/step - loss: 0.1255 - val_loss: 0.1415\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 3s 418us/step - loss: 0.1254 - val_loss: 0.1416\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 3s 389us/step - loss: 0.1254 - val_loss: 0.1416\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 3s 379us/step - loss: 0.1253 - val_loss: 0.1417\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 3s 385us/step - loss: 0.1253 - val_loss: 0.1417\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 3s 383us/step - loss: 0.1252 - val_loss: 0.1418\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: 0.1251 - val_loss: 0.1418\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 3s 390us/step - loss: 0.1251 - val_loss: 0.1419\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 3s 388us/step - loss: 0.1250 - val_loss: 0.1419\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 3s 389us/step - loss: 0.1249 - val_loss: 0.1420\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 3s 386us/step - loss: 0.1249 - val_loss: 0.1420\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 3s 408us/step - loss: 0.1248 - val_loss: 0.1421\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 3s 400us/step - loss: 0.1248 - val_loss: 0.1421\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 3s 381us/step - loss: 0.1247 - val_loss: 0.1421\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 3s 391us/step - loss: 0.1246 - val_loss: 0.1422\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 3s 380us/step - loss: 0.1246 - val_loss: 0.1422\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 3s 406us/step - loss: 0.1245 - val_loss: 0.1423\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 3s 395us/step - loss: 0.1244 - val_loss: 0.1423\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 3s 388us/step - loss: 0.1244 - val_loss: 0.1424\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 3s 378us/step - loss: 0.1243 - val_loss: 0.1424\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X,y,epochs=100,batch_size=5,verbose=1,validation_split=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: matplotlib.pyplot as plt\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inlineimport matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X.iloc[0:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability for each of the examples belonging to class 1: \n",
      "[[0.00468563]\n",
      " [0.38649455]\n",
      " [0.00481594]\n",
      " [0.96284145]\n",
      " [0.99802715]\n",
      " [0.00301919]\n",
      " [0.39244363]\n",
      " [0.00263148]\n",
      " [0.00916286]\n",
      " [0.99682826]]\n",
      "Predicted class label for each of the examples: \n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    " # print the predicted classes\n",
    "print(\"Predicted probability for each of the examples belonging to class 1: \"),\n",
    "print(y_predicted)\n",
    "print(\"Predicted class label for each of the examples: \"), \n",
    "print(np.round(y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
